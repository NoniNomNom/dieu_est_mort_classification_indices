{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEMARRER ICI SI AUCUN DATASET DE QUESTIONS DISPO ###\n",
    "### SINON VOIR PLUS LOIN ###\n",
    "\n",
    "import openpyxl\n",
    "import polars as pl\n",
    "\n",
    "print(\"load\")\n",
    "wb = openpyxl.load_workbook('data.xlsx')\n",
    "print(\"loaded\")\n",
    "ws = wb.active\n",
    "\n",
    "label = [str(ws.cell(row=i,column=1).value) for i in range(1+1,ws.max_row+1)]\n",
    "titre = [ws.cell(row=i,column=2).value for i in range(1+1,ws.max_row+1)]\n",
    "texte = [ws.cell(row=i,column=3).value for i in range(1+1,ws.max_row+1)]\n",
    "\n",
    "ids = list(range(0,len(label)))\n",
    "\n",
    "\n",
    "print(label)\n",
    "print(titre)\n",
    "print(texte)\n",
    "df = pl.DataFrame(\n",
    "    {   \"label\" : label,\n",
    "        \"titre\" : titre,\n",
    "        \"texte\": texte,\n",
    "        \"id\" : ids\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)\n",
    "print(df[0,1])\n",
    "print(len(df))\n",
    "\n",
    "id2label = dict(zip(ids, label))\n",
    "label2id = dict(zip(label, ids))\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "df_questions = pl.DataFrame(\n",
    "    {   \"id\" : [],\n",
    "        \"question\" : [],\n",
    "    },\n",
    "    schema=[(\"id\", pl.Int64), (\"question\", pl.String)]\n",
    "    )\n",
    "\n",
    "n = len(df)\n",
    "model='wizardlm2:7b'\n",
    "\n",
    "for i in range(0, n):\n",
    "\n",
    "    prompt = \"\"\"Tu aides à la création d'un jeu d'enquête nommé \"Dieu est mort\".\n",
    "    Le principe du jeu est le suivant : Dieu est mort, quatre archanges et cinq princes-démons figurent sur la liste des suspects.\n",
    "    Chaque joueur incarne un archange ou un prince-démon. Les joueurs doivent découvrir ce qui est arrivé à Dieu, en discutant entre eux et en obtenant des indices. \n",
    "    Sans mentionner l'indice, crée 20 possibles questions à poser au maître du jeu pour obtenir l'indice suivant : \"\"\" + str(df[i,1]) + \" : \" + str(df[i,2])\n",
    "\n",
    "    generated = ollama.generate(model=model, #choisir un modèle\n",
    "                            prompt=prompt)\n",
    "\n",
    "    id = str(df[i,3])\n",
    "    res = generated[\"response\"]\n",
    "    res_list = res.split(\"\\n\")\n",
    "\n",
    "    id_arr = [int(id)] * len(res_list)\n",
    "    print(id_arr)\n",
    "\n",
    "    df_temp = pl.DataFrame(\n",
    "    {   \"id\" : id_arr,\n",
    "        \"question\" : res_list,\n",
    "    }\n",
    "    )\n",
    "\n",
    "    df_questions = pl.concat(\n",
    "        [df_questions, df_temp]\n",
    "    )\n",
    "\n",
    "print(df_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "path = \"questions_\" + model + \".csv\"\n",
    "                    \n",
    "df_questions.write_csv(path,\n",
    "                       separator=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POUR GENERER DES QUESTIONS SUPPLEMENTAIRES POUR UN INDICE SPECIFIQUE\n",
    "\n",
    "import ollama\n",
    "\n",
    "df_questions = pl.DataFrame(\n",
    "    {   \"id\" : [],\n",
    "        \"question\" : [],\n",
    "    },\n",
    "    schema=[(\"id\", pl.Int64), (\"question\", pl.String)]\n",
    "    )\n",
    "\n",
    "i = 5\n",
    "model='wizardlm2:7b' # choisir modèle\n",
    "\n",
    "prompt = \"\"\"Tu aides à la création d'un jeu d'enquête nommé \"Dieu est mort\".\n",
    "Le principe du jeu est le suivant : Dieu est mort, quatre archanges et cinq princes-démons figurent sur la liste des suspects.\n",
    "Chaque joueur incarne un archange ou un prince-démon. Les joueurs doivent découvrir ce qui est arrivé à Dieu, en discutant entre eux et en obtenant des indices. \n",
    "Sans mentionner l'indice, crée 5 possibles questions à poser au maître du jeu pour obtenir l'indice suivant : \"\"\" + str(df[i,1]) + \" : \" + str(df[i,2])\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "generated = ollama.generate(model=model,\n",
    "                        prompt=prompt)\n",
    "\n",
    "id = str(df[i,3])\n",
    "res = generated[\"response\"]\n",
    "res_list = res.split(\"\\n\")\n",
    "\n",
    "id_arr = [int(id)] * len(res_list)\n",
    "print(id_arr)\n",
    "\n",
    "df_temp = pl.DataFrame(\n",
    "{   \"id\" : id_arr,\n",
    "    \"question\" : res_list,\n",
    "}\n",
    ")\n",
    "\n",
    "df_questions = pl.concat(\n",
    "    [df_questions, df_temp]\n",
    ")\n",
    "\n",
    "print(df_questions)\n",
    "\n",
    "path = \"questions_\" + str(i) + \"_\" + model + \".csv\"\n",
    "                    \n",
    "df_questions.write_csv(path,\n",
    "                       separator=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES\n",
    "\n",
    "Modèles utilisés pour la génération de questions :\n",
    "- Openhermes 2.5 7B\n",
    "- Gemma 7B\n",
    "- Gemma 2 9B\n",
    "- Gemma 2 27B\n",
    "- Mistral-Nemo\n",
    "- Orca2 13B\n",
    "- WizardLM2 7B\n",
    "\n",
    "\n",
    "Nettoyage : \n",
    "- Assembler les multiples csv en un seul nommé \"questions_all.csv\". Nettoyage manuel possiblement nécessaire (supprimer numéros de questions, signes et lignes inutiles, espaces en trop...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEMARRER ICI SI DATASET DE QUESTIONS DEJA GENERE ###\n",
    "\n",
    "import polars as pl \n",
    "df_questions = pl.read_csv(source=\"questions_all.csv\", \n",
    "                           has_header=True,\n",
    "                           separator= ';')\n",
    "df_questions.columns = [\"label\", \"text\"]\n",
    "\n",
    "print(df_questions)\n",
    "\n",
    "num_labels = len(df_questions[\"label\"].unique())\n",
    "print(num_labels)\n",
    "\n",
    "print(df_questions[\"label\"].unique().sort())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train, test = train_test_split(df_questions, test_size=0.1)\n",
    "\n",
    "train, eval = train_test_split(train, test_size=0.1)\n",
    "\n",
    "eval_db = eval[\"text\"]\n",
    "\n",
    "x = []\n",
    "for i in range(len(eval_db)):\n",
    "    y = eval_db[i][:512]\n",
    "    x.append(y)\n",
    "eval_db = x\n",
    "\n",
    "data_train = Dataset.from_polars(train,\n",
    "                           split=\"train\")\n",
    "\n",
    "data_test = Dataset.from_polars(test,\n",
    "                           split=\"test\")\n",
    "\n",
    "print(data_train)\n",
    "print(data_train[\"label\"])\n",
    "print(data_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./distilbert-base-multilingual-cased\")\n",
    "\n",
    "def preprocess_function(database):\n",
    "    return tokenizer(database[\"text\"], \n",
    "                     truncation=True\n",
    "                     )\n",
    "\n",
    "\n",
    "tokenized_train = data_train.map(preprocess_function, batched=True)\n",
    "tokenized_test = data_test.map(preprocess_function, batched=True)\n",
    "\n",
    "print(tokenized_train)\n",
    "\n",
    "print(tokenized_train[\"text\"])\n",
    "print(tokenized_train[\"label\"])\n",
    "print(tokenized_train[\"input_ids\"])\n",
    "print(tokenized_train[\"attention_mask\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2titre = dict(zip(ids, titre))\n",
    "titre2id = dict(zip(titre, ids))\n",
    "print(id2titre)\n",
    "print(titre2id)\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./distilbert-base-multilingual-cased\",\n",
    "    num_labels = num_labels,\n",
    "    id2label=id2titre, \n",
    "    label2id=titre2id)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\n",
    "    output_dir=\"model_classif\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=16,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", \n",
    "                      model = \"./model_classif/checkpoint-2576/\", \n",
    "                      device = \"cuda\")\n",
    "\n",
    "result = classifier(\"Que s'est-il passé en yougoslavie ?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import polars as pl\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "classifier = pipeline(\"text-classification\", \n",
    "                      model = \"./model_classif/checkpoint-2576/\", \n",
    "                      device = \"cuda\")\n",
    "\n",
    "result = classifier(eval_db)\n",
    "print(result)\n",
    "pred = []\n",
    "\n",
    "for i in range(len(result)):\n",
    "    x = result[i][\"label\"]\n",
    "    pred.append(x)\n",
    "\n",
    "eval = pl.DataFrame(eval)\n",
    "eval = eval.select(\"label\").cast(pl.String)\n",
    "true = eval.with_columns(label = pl.col(\"label\").replace(id2titre))\n",
    "\n",
    "df_results = pl.DataFrame({\n",
    "    \"true\":true,\n",
    "    \"pred\":pred\n",
    "\n",
    "})\n",
    "\n",
    "conf = confusion_matrix(true, pred)\n",
    "\n",
    "accuracy = accuracy_score(true, pred)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "report = classification_report(true, pred)\n",
    "\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
